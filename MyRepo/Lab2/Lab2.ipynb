{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing on Global Land Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget \"https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/GLT_filtered.csv\" -O GLT_filtered.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the Global Land Temperature dataset as a list of lists. Before starting, take a moment to bet\u0002ter inspect the attributes you are going to work on. How many of them are nominal, how many\n",
    "continuous or discrete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Analyze the attribute AverageTemperature, which contains missing values. Fill any gap with the arithmetic mean among the closest antecedent and the closest successive measurements in time, taken in the same city. Assume the following rules for edge cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. it can happen that a missing value does not have a preceding (or successive) measurement. This happens when the missing value is the first (or last) value of the dataset. If this is the case, consider the missing value to be preceded (or followed) by a 0, then compute the mean accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. if there are consecutive missing values, just compute them in temporal order and use the newly inserted values to evaluate the following ones. Here it is an example with a simple list where both (a) and (b) rules have been applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisco le funzioni per il calcolo delle medie di temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_calc_df_init(df):\n",
    "    if np.isnan(df['AverageTemperature_filled']) and df['row_num'] == 1:\n",
    "        return df['next_not_null_AvgTemp']/2\n",
    "    else: \n",
    "        return df['AverageTemperature_filled']\n",
    "\n",
    "def mean_calc_df_last(df):\n",
    "    if np.isnan(df['AverageTemperature_filled']):\n",
    "        return df['prev_not_null_AvgTemp']/2\n",
    "    else: \n",
    "        return df['AverageTemperature_filled']\n",
    "\n",
    "def mean_calc_df(df):\n",
    "    if np.isnan(df['AverageTemperature_filled']):\n",
    "        v = sum([2**i for i in range(0,df['consective_nones_pos'])])\n",
    "        return (df['prev_not_null_AvgTemp'] + df['next_not_null_AvgTemp']*v)/(2**(df['consective_nones_pos']))\n",
    "    else: \n",
    "        return df['AverageTemperature_filled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo i dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered = pd.read_csv('GLT_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasformo il tipo di 'Date' in date e 'AverageTemperature' in valore numerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['Date'] = pd.to_datetime(GLT_filtered['Date'], format = '%Y-%m-%d')\n",
    "GLT_filtered['AverageTemperature'] = pd.to_numeric(GLT_filtered['AverageTemperature']) \n",
    "# pd.to_numeric(GLT_filtered['AverageTemperature'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo la colonna che ospiterà le temperature medie senza NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['AverageTemperature_filled'] = GLT_filtered['AverageTemperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungo il numero del record per ciascuna sezione relativa alle città"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['row_num'] = GLT_filtered\\\n",
    "    .groupby(['City'])\\\n",
    "    .cumcount()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungo colonna con prime temperature medie successive non NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['next_not_null_AvgTemp'] = GLT_filtered['AverageTemperature_filled']\n",
    "GLT_filtered['next_not_null_AvgTemp'] = GLT_filtered\\\n",
    "    .groupby(['City'])['next_not_null_AvgTemp']\\\n",
    "    .backfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do il valore iniziale alla temperatura media nel caso in cui sia NAN nel primo record relativo a una città"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['AverageTemperature_filled'] = GLT_filtered.apply(mean_calc_df_init, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungo colonna con prime temperature medie precedenti non NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['prev_not_null_AvgTemp'] = GLT_filtered['AverageTemperature_filled']\n",
    "GLT_filtered['prev_not_null_AvgTemp'] = GLT_filtered\\\n",
    "    .groupby(['City'])['prev_not_null_AvgTemp']\\\n",
    "    .ffill()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggiungo colonna con check valori nulli ({0,1}) in 'AverageTemperature_filled', colonna di appoggio con cumsum e colonna di appoggio con cumsum raggruppata su colonna precedente e su 'Città' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['avg_is_none'] = 0\n",
    "GLT_filtered.loc[GLT_filtered['AverageTemperature_filled'].isnull(), 'avg_is_none'] = 1\n",
    "GLT_filtered['consective_nones'] = (GLT_filtered['avg_is_none'] != GLT_filtered['avg_is_none'].shift(1)).cumsum()\n",
    "GLT_filtered['consective_nones_pos'] = GLT_filtered\\\n",
    "    .groupby(['City','consective_nones'])['avg_is_none']\\\n",
    "    .cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applico funzione per riempire i NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['AverageTemperature_filled'] = GLT_filtered.apply(mean_calc_df, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applico funzione per eliminare i NAN rimanenti sugli ultimi record di ogni sezione 'Città'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered['AverageTemperature_filled'] = GLT_filtered.apply(mean_calc_df_last, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino colonne di appoggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLT_filtered = GLT_filtered.drop(['row_num', 'next_not_null_AvgTemp','prev_not_null_AvgTemp', 'avg_is_none', 'consective_nones','consective_nones_pos'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = GLT_filtered[GLT_filtered['AverageTemperature_filled'].isnull()]\n",
    "# b = GLT_filtered.groupby('City').first()\n",
    "# c = GLT_filtered.groupby('City').last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a function that, given the name of a city and an integer N > 0, prints:  \n",
    "    a. the top N hottest measurements;  \n",
    "    b. the top N coldest measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_temperatures_city(df, name):\n",
    "    df_out = df[df['City'] == name] \n",
    "    df_out_1 = df_out.nlargest(10,'AverageTemperature_filled')\n",
    "    df_out_2 = df_out.nsmallest(10,'AverageTemperature_filled')\n",
    "    return (df_out_1,df_out_2)\n",
    "    # return(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest,lowest = top_temperatures_city(df=GLT_filtered,name='Aleppo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textual data preparation on IMDB reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the IMDb dataset as a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclimdb_reviews_train = []\n",
    "with open('aclimdb_reviews_train.txt', encoding=\"utf8\") as f:\n",
    "    for row in f:\n",
    "        aclimdb_reviews_train.append(row)\n",
    "aclimdb_reviews_train = aclimdb_reviews_train[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Apply the tokenization function listed below to your reviews. Please refer to the function’s docstring 1 for the input and output parameters. The tokenization procedure splits each comment in tokens (i.e. separate words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def tokenize(docs):\n",
    "    \"\"\"Compute the tokens for each document.\n",
    "    Input: a list of strings. Each item is a document to tokenize.\n",
    "    Output: a list of lists. Each item is a list containing the tokens of the\n",
    "    relative document.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for doc in docs:\n",
    "        for punct in string.punctuation:\n",
    "            doc = doc.replace(punct, \" \")\n",
    "        split_doc = [ token.lower() for token in doc.split(\" \") if token ]\n",
    "        tokens.append(split_doc)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclimdb_reviews_train_tokenized = tokenize(aclimdb_reviews_train)\n",
    "\n",
    "# aclimdb_reviews_train_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The next step requires the computation of the term frequency (TF) of each token within its respective document. Although there exist different techniques to evaluate the frequency, we will now assume that the TF of a token t in a document d is equal to the number of occurrences of t in d. Compute the TF for all your reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def words_counter(docs):\n",
    "    dicts = []\n",
    "    for doc in docs:\n",
    "        # print(dict(Counter(doc)))\n",
    "        dicts.append(dict(Counter(doc)))\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclimdb_reviews_train_dicts = words_counter(aclimdb_reviews_train_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We will now compute the inverse document frequency (IDF). While the TF gives an idea of the weight of a token within a document, the IDF is used to find its significance among the entire collection of documents (i.e. your reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_words_all(docs):\n",
    "    set_words = set()\n",
    "    for doc in docs:\n",
    "        set_words = set_words.union(set(doc))\n",
    "    return set_words\n",
    "\n",
    "def set_words_doc(docs):\n",
    "    set_words_list = list()\n",
    "    for doc in docs:\n",
    "        set_words_list = set_words_list.append(set(doc))\n",
    "    return set_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aclimdb_reviews_train_set_words = set_words_all(aclimdb_reviews_train_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', 'a', 'v'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aclimdb_reviews_train_list_of_set_words = set_words_doc(aclimdb_reviews_train_tokenized)\n",
    "set_words_all([['a','a','a','a','a','1','1','1','1','v']])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9912e19f637bc0bbddfba41d0db5acc7b7f7d78291050fc62af43d5b08367c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('data_science_lab': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
